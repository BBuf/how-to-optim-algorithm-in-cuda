## how-to-optim-algorithm-in-cuda

> æˆ‘ä¹Ÿç»´æŠ¤äº†ä¸€ä¸ªå­¦ä¹ æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆPyTorchå’ŒOneFlowï¼‰çš„ä»“åº“ https://github.com/BBuf/how-to-learn-deep-learning-framework ä»¥åŠä¸€ä¸ªå¦‚ä½•å­¦ä¹ æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ï¼ˆTVM/MLIR/LLVMï¼‰çš„å­¦ä¹ ä»“åº“ https://github.com/BBuf/tvm_mlir_learn , æœ‰éœ€è¦çš„å°ä¼™ä¼´å¯ä»¥**ç‚¹ä¸€ç‚¹star**

æœ¬å·¥ç¨‹è®°å½•å¦‚ä½•åŸºäº cuda ä¼˜åŒ–ä¸€äº›å¸¸è§çš„ç®—æ³•ã€‚è¯·æ³¨æ„ï¼Œä¸‹é¢çš„ä»‹ç»éƒ½åˆ†åˆ«å¯¹åº”äº†å­ç›®å½•çš„ä»£ç å®ç°ï¼Œæ‰€ä»¥æƒ³å¤ç°æ€§èƒ½çš„è¯è¯·æŸ¥çœ‹å¯¹åº”å­ç›®å½•ä¸‹é¢çš„ README ã€‚

> å‹æƒ…é“¾æ¥ï¼šhttps://github.com/DefTruth/CUDA-Learn-Notes

### 0. **cuda-mode**

- è¯¾ç¨‹çš„ Slides å’Œ è„šæœ¬ï¼šhttps://github.com/cuda-mode/lectures
- è¯¾ç¨‹åœ°å€ï¼šhttps://www.youtube.com/@CUDAMODE
- æˆ‘çš„è¯¾ç¨‹ç¬”è®°ï¼šhttps://github.com/BBuf/how-to-optim-algorithm-in-cuda/tree/master/cuda-mode

ä¸€ç›´æƒ³ç³»ç»Ÿçœ‹ä¸€ä¸‹æŸä¸ªè¯¾ç¨‹ç³»ç»Ÿå’Œç§‘å­¦çš„å­¦ä¹ ä¸‹ CUDA ï¼Œæ„Ÿè§‰ CUDA-MODE è¿™ä¸ªè¯¾ç¨‹èƒ½æ»¡è¶³æˆ‘çš„éœ€æ±‚ã€‚è¿™ä¸ªè¯¾ç¨‹æ˜¯å‡ ä¸ª PyTorch çš„ Core Dev æçš„ï¼Œæ¯”è¾ƒç³»ç»Ÿå’Œä¸“ä¸šã€‚ä¸è¿‡ç”±äºè¿™ä¸ªè¯¾ç¨‹æ˜¯ Youtube ä¸Šçš„è‹±è¯­è¯¾ç¨‹ï¼Œæ‰€ä»¥è¦å­¦ä¹ å’Œç†è§£è¿™ä¸ªè¯¾ç¨‹è¿˜æ˜¯éœ€è¦èŠ±ä¸å°‘æ—¶é—´çš„ï¼Œæˆ‘è¿™é‡Œè®°å½•ä¸€ä¸‹å­¦ä¹ è¿™ä¸ªè¯¾ç¨‹çš„æ¯ä¸€è¯¾çš„ç¬”è®°ï¼Œå¸Œæœ›å¯ä»¥é€šè¿‡è¿™ä¸ªç¬”è®°å¸®åŠ©å¯¹è¿™ä¸ªè¯¾ç¨‹ä»¥åŠ CUDA æ„Ÿå…´è¶£çš„è¯»è€…æ›´å¿«å¸æ”¶è¿™ä¸ªè¯¾ç¨‹çš„çŸ¥è¯†ã€‚è¿™ä¸ªè¯¾ç¨‹ç›¸æ¯”äºä»¥å‰çš„çº¯æ•™ç¨‹æ›´åŠ å…³æ³¨çš„æ˜¯æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ CUDA åšä»€ä¹ˆäº‹æƒ…ï¼Œè€Œä¸æ˜¯è®©è¯»è€…é™·å…¥åˆ° CUDA ä¸“ä¸šæœ¯è¯­çš„ç»†èŠ‚ä¸­ï¼Œé‚£ä¼šéå¸¸ç—›è‹¦ã€‚ä¼Ÿå¤§æ— éœ€å¤šè¨€ï¼Œæ„Ÿå…´è¶£è¯·é˜…è¯»æœ¬æ–‡ä»¶å¤¹ä¸‹çš„å„ä¸ªè¯¾ç¨‹çš„å­¦ä¹ ç¬”è®°ã€‚


### 1. how-to-compile-pytorch-from-source

è®°å½•å¦‚ä½•æ‰‹åŠ¨ç¼–è¯‘ PyTorch æºç ï¼Œå­¦ä¹  PyTorch çš„ä¸€äº› cuda å®ç°ã€‚

### 2. reduce

è¿™é‡Œè®°å½•å­¦ä¹  NIVDIA çš„[reduceä¼˜åŒ–å®˜æ–¹åšå®¢](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf) åšçš„ç¬”è®°ã€‚å®Œæ•´å®éªŒä»£ç è§[è¿™é‡Œ](https://github.com/BBuf/how-to-optim-algorithm-in-cuda/tree/master/reduce) , åŸç†è®²è§£è¯·çœ‹ï¼š[ã€BBufçš„CUDAç¬”è®°ã€‘ä¸‰ï¼Œreduceä¼˜åŒ–å…¥é—¨å­¦ä¹ ç¬”è®°](https://zhuanlan.zhihu.com/p/596012674) ã€‚åç»­åˆæ·»åŠ äº† PyTorch BlockReduce æ¨¡æ¿ä»¥åŠåœ¨è¿™ä¸ªæ¨¡æ¿çš„åŸºç¡€ä¸Šé¢å¤–åŠ äº†ä¸€ä¸ªæ•°æ® Pack ,åˆè·å¾—äº†ä¸€äº›å¸¦å®½çš„æå‡ã€‚è¯¦ç»†æ•°æ®å¦‚ä¸‹ï¼š

æ€§èƒ½å’Œå¸¦å®½çš„æµ‹è¯•æƒ…å†µå¦‚ä¸‹ (A100 PCIE 40G)ï¼š

![å›¾ç‰‡](https://user-images.githubusercontent.com/35585791/213908763-480d0c07-5709-4829-9903-db17a0ecca89.png)

### 3. elementwise

å°† oneflow çš„ elementwise æ¨¡æ¿æŠ½å‡ºæ¥æ–¹ä¾¿å¤§å®¶ä½¿ç”¨ï¼Œè¿™ä¸ª elementwise æ¨¡æ¿å®ç°äº†é«˜æ•ˆçš„æ€§èƒ½å’Œå¸¦å®½åˆ©ç”¨ç‡ï¼Œå¹¶ä¸”ç”¨æ³•éå¸¸çµæ´»ã€‚å®Œæ•´å®éªŒä»£ç è§[è¿™é‡Œ](https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/master/elementwise/elementwise.cu) ï¼ŒåŸç†è®²è§£è¯·çœ‹ï¼š[ã€BBuf çš„CUDAç¬”è®°ã€‘ä¸€ï¼Œè§£æOneFlow Element-Wise ç®—å­å®ç°](https://zhuanlan.zhihu.com/p/591058808) ã€‚è¿™é‡Œä»¥é€ç‚¹ä¹˜ä¸ºä¾‹ï¼Œæ€§èƒ½å’Œå¸¦å®½çš„æµ‹è¯•æƒ…å†µå¦‚ä¸‹ (A100 PCIE 40G)ï¼š

|ä¼˜åŒ–æ‰‹æ®µ|æ•°æ®ç±»å‹|è€—æ—¶(us)|å¸¦å®½åˆ©ç”¨ç‡|
|--|--|--|--|
|naive elementwise|float|298.46us|85.88%|
|oneflow elementwise|float|284us|89.42%|
|naive elementwise|half|237.28us|52.55%|
|oneflow elementwise|half|140.74us|87.31%|

å¯ä»¥çœ‹åˆ°æ— è®ºæ˜¯æ€§èƒ½è¿˜æ˜¯å¸¦å®½ï¼Œä½¿ç”¨ oneflow çš„ elementwise æ¨¡æ¿ç›¸æ¯”äºåŸå§‹å®ç°éƒ½æœ‰è¾ƒå¤§æå‡ã€‚

### 4. FastAtomicAdd

å®ç°çš„è„šæœ¬æ˜¯é’ˆå¯¹halfæ•°æ®ç±»å‹åšå‘é‡çš„å†…ç§¯ï¼Œç”¨åˆ°äº†atomicAddï¼Œä¿è¯æ•°æ®çš„é•¿åº¦ä»¥åŠgridsizeå’Œblocksizeéƒ½æ˜¯å®Œå…¨ä¸€è‡´çš„ã€‚ä¸€å…±å®ç°äº†3ä¸ªè„šæœ¬ï¼š

1. https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/master/FastAtomicAdd/atomic_add_half.cu çº¯halfç±»å‹çš„atomicAddã€‚
2. https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/master/FastAtomicAdd/atomic_add_half_pack2.cu half+packï¼Œæœ€ç»ˆä½¿ç”¨çš„æ˜¯half2ç±»å‹çš„atomicAddã€‚
3. https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/master/FastAtomicAdd/fast_atomic_add_half.cu å¿«é€ŸåŸå­åŠ ï¼Œè™½ç„¶æ²¡æœ‰æ˜¾ç¤ºçš„packï¼Œä½†æœ¬è´¨ä¸Šä¹Ÿæ˜¯é€šè¿‡å¯¹å•ä¸ªhalfè¡¥0ä½¿ç”¨ä¸Šäº†half2çš„åŸå­åŠ ã€‚

æ€§èƒ½å’Œå¸¦å®½çš„æµ‹è¯•æƒ…å†µå¦‚ä¸‹ (A100 PCIE 40G)ï¼š

|åŸå­åŠ æ–¹å¼|æ€§èƒ½(us)|
|--|--|
|çº¯halfç±»å‹|422.36ms|
|pack half2ç±»å‹|137.02ms|
|fastAtomicAdd|137.01ms|

å¯ä»¥çœ‹åˆ°ä½¿ç”¨pack halfçš„æ–¹å¼å’Œç›´æ¥ä½¿ç”¨halfçš„fastAtomicAddæ–¹å¼å¾—åˆ°çš„æ€§èƒ½ç»“æœä¸€è‡´ï¼Œå‡æ¯”åŸå§‹çš„halfçš„åŸå­åŠ å¿«3-4å€ã€‚

### 5. UpsampleNearest2D

upsample_nearest_2d.cu å±•ç¤ºäº† oneflow å¯¹ upsample_nearest2d çš„å‰åå‘çš„ä¼˜åŒ– kernel çš„ç”¨æ³•ï¼Œæ€§èƒ½å’Œå¸¦å®½çš„æµ‹è¯•æƒ…å†µå¦‚ä¸‹ (A100 PCIE 40G)ï¼š

|æ¡†æ¶|æ•°æ®ç±»å‹|Opç±»å‹|å¸¦å®½åˆ©ç”¨ç‡|è€—æ—¶|
|--|--|--|--|--|
| PyTorch | Float32 | UpsampleNearest2D forward | 28.30% | 111.42us |
| PyTorch | Float32 | UpsampleNearest2D backward | 60.16% | 65.12us |
| OneFlow | Float32 |UpsampleNearest2D forward | 52.18% | 61.44us |
| OneFlow | Float32 |UpsampleNearest2D backward | 77.66% | 50.56us |
| PyTorch | Float16 | UpsampleNearest2D forward | 16.99% | 100.38us |
| PyTorch | Float16 | UpsampleNearest2D backward | 31.56% | 57.38us |
| OneFlow | Float16 |UpsampleNearest2D forward | 43.26% | 35.36us |
| OneFlow | Float16 |UpsampleNearest2D backward | 44.82% | 40.26us |

å¯ä»¥çœ‹åˆ°åŸºäº oneflow upsample_nearest2d çš„å‰åå‘çš„ä¼˜åŒ– kernel å¯ä»¥è·å¾—æ›´å¥½çš„å¸¦å®½åˆ©ç”¨ç‡å’Œæ€§èƒ½ã€‚æ³¨æ„è¿™é‡Œçš„ profile ä½¿ç”¨çš„æ˜¯ oneflow è„šæœ¬ï¼Œè€Œä¸æ˜¯ upsample_nearest_2d.cu ï¼Œè¯¦æƒ…è¯·çœ‹ [UpsampleNearest2D/README.md](UpsampleNearest2D/README.md) ã€‚


### 6. indexing

åœ¨ PyTorch ä¸­å¯¹ index_add åšäº†æè‡´çš„ä¼˜åŒ–ï¼Œæˆ‘è¿™é‡Œå°† [PyTorch çš„ index_add å®ç°](indexing/index_add_cuda_pytorch_impl.cu) è¿›è¡Œäº†å‰¥ç¦»ï¼Œæ–¹ä¾¿å¤§å®¶åº”ç”¨äºå…¶å®ƒæ¡†æ¶ã€‚å…·ä½“è¯·çœ‹ indexing æ–‡ä»¶å¤¹çš„ README ã€‚å…¶ä¸­è¿˜æœ‰å’Œ oneflow çš„ index_add å®ç°çš„å„ä¸ª case çš„æ€§èƒ½æ¯”è¾ƒç»“æœã€‚æ•´ä½“æ¥è¯´ PyTorch åœ¨ index Tensorå…ƒç´ å¾ˆå°ï¼Œä½†Tensorå¾ˆå¤§çš„æƒ…å†µä¸‹æœ‰è¾ƒå¤§çš„æ€§èƒ½æå‡ï¼Œå…¶å®ƒæƒ…å†µå’Œ OneFlow åŸºæœ¬æŒå¹³ã€‚è¯¦æƒ…è¯·çœ‹ [indexing/README.md](indexing/README.md) ã€‚

### 7. oneflow-cuda-optimize-skills

OneFlow æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­åŸºäº cuda åšçš„ä¼˜åŒ–å·¥ä½œï¼ŒåŠ¨æ€æ›´æ–°ä¸­ã€‚

### 8. FastTransformer

æ€»ç»“ FastTransformer ç›¸å…³çš„ cuda ä¼˜åŒ–æŠ€å·§ã€‚[README_BERT.md](FastTransformer/README_BERT.md) æ€»ç»“äº† BERT ç›¸å…³çš„ä¼˜åŒ–æŠ€å·§ã€‚

### 9. softmax

å­¦ä¹ äº†oneflowçš„softmax kernelå®ç°ä»¥åŠFaster Transformer softmax kernelçš„å®ç°ï¼Œå¹¶ä»¥ä¸ªäººçš„è§’åº¦åˆ†åˆ«è§£æäº†åŸç†å’Œä»£ç å®ç°ï¼Œæœ€åå¯¹æ€§èƒ½åšä¸€ä¸ªå¯¹æ¯”æ–¹ä¾¿å¤§å®¶ç›´è§‚çš„æ„Ÿå—åˆ°oneflow softmax kernelç›¸æ¯”äºFasterTransformerçš„ä¼˜è¶Šæ€§ã€‚

### 10. linear-attention

å­¦ä¹ ä¸€äº› linear attention çš„ cuda ä¼˜åŒ–æŠ€å·§ã€‚

![å›¾ç‰‡](https://user-images.githubusercontent.com/35585791/221142822-1c2ef670-00e2-4782-98de-d35a4eebd33c.png)

### 11. large-language-model-note

æ”¶é›†äº†å’Œå¤§è¯­è¨€æ¨¡å‹åŸç†ï¼Œè®­ç»ƒï¼Œæ¨ç†ï¼Œæ•°æ®æ ‡æ³¨çš„ç›¸å…³æ–‡ç« ã€‚

### 12. mlsys-paper

å‰ç ”çš„å¤§æ¨¡å‹è®­ç»ƒç›¸å…³ AI-Infra è®ºæ–‡æ”¶é›†ä»¥åŠé˜…è¯»ç¬”è®°ã€‚ 

### 13. triton

Triton å­¦ä¹ è¿‡ç¨‹ä¸­çš„ä»£ç è®°å½•å’Œå­¦ä¹ ç¬”è®°ã€‚

### 14. meagtron-lm

Meagtron-LM å­¦ä¹ ç¬”è®°ã€‚

### 15. triton-meetup

Triton ä¸­å›½ä¸¾åŠçš„ Meetup çš„slidesæ±‡æ€»ã€‚ç‚¹å¡è¿™ä¸ªæ–‡ä»¶å¤¹ä¹Ÿå¯ä»¥æ‰¾åˆ°å¯¹åº”çš„Meetupçš„è§†é¢‘å›æ”¾ã€‚

### 16. ptx-isa

å¯¹ CUDA PTX ISA æ–‡æ¡£çš„ä¸€ä¸ªç¿»è¯‘å’Œå­¦ä¹ ã€‚

### 17. pytorch-blog-codes

å¯¹ PyTorch å›¢é˜Ÿå‘å¸ƒçš„ cuda æŠ€æœ¯çš„ä¸€äº›å­¦ä¹ ç¬”è®°ã€‚

### 18. cutlass

cutlass ç›¸å…³çš„å­¦ä¹ ç¬”è®°ã€‚

### 19. cuda-paper

cuda ç›¸å…³çš„ paper çš„é˜…è¯»ã€‚

### 20. åŸåˆ›å­¦ä¹ ç¬”è®°

<details>
<summary>ç‚¹å‡»å±•å¼€/æ”¶èµ· BBuf çš„ CUDA å­¦ä¹ ç¬”è®°åˆ—è¡¨</summary>

- [ã€BBufçš„CUDAç¬”è®°ã€‘ä¸€ï¼Œè§£æOneFlow Element-Wise ç®—å­å®ç°](https://zhuanlan.zhihu.com/p/591058808)
- [ã€BBufçš„CUDAç¬”è®°ã€‘äºŒï¼Œè§£æ OneFlow BatchNorm ç›¸å…³ç®—å­å®ç°](https://zhuanlan.zhihu.com/p/593483751)
- [ã€BBufçš„CUDAç¬”è®°ã€‘ä¸‰ï¼Œreduceä¼˜åŒ–å…¥é—¨å­¦ä¹ ç¬”è®°](https://zhuanlan.zhihu.com/p/596012674)
- [ã€BBufçš„CUDAç¬”è®°ã€‘å››ï¼Œä»‹ç»ä¸‰ä¸ªé«˜æ•ˆå®ç”¨çš„CUDAç®—æ³•å®ç°ï¼ˆOneFlow ElementWiseæ¨¡æ¿ï¼ŒFastAtomicAddæ¨¡æ¿ï¼ŒOneFlow UpsampleNearest2dæ¨¡æ¿ï¼‰](https://zhuanlan.zhihu.com/p/597435971)
- [ã€BBufçš„CUDAç¬”è®°ã€‘äº”ï¼Œè§£è¯» PyTorch index_add æ“ä½œæ¶‰åŠçš„ä¼˜åŒ–æŠ€æœ¯](https://zhuanlan.zhihu.com/p/599085070)
- [ã€BBufçš„CUDAç¬”è®°ã€‘å…­ï¼Œæ€»ç»“ FasterTransformer Encoder(BERT) çš„cudaç›¸å…³ä¼˜åŒ–æŠ€å·§](https://zhuanlan.zhihu.com/p/601130731)
- [ã€BBufçš„CUDAç¬”è®°ã€‘ä¸ƒï¼Œæ€»ç»“ FasterTransformer Decoder(GPT) çš„cudaç›¸å…³ä¼˜åŒ–æŠ€å·§](https://zhuanlan.zhihu.com/p/603611192)
- [ã€BBufçš„CUDAç¬”è®°ã€‘å…«ï¼Œå¯¹æ¯”å­¦ä¹ OneFlow å’Œ FasterTransformer çš„ Softmax Cudaå®ç°](https://zhuanlan.zhihu.com/p/609198294)
- [ã€BBufçš„CUDAç¬”è®°ã€‘ä¹ï¼Œä½¿ç”¨newbingï¼ˆchatgptï¼‰è§£æoneflow softmaxç›¸å…³çš„fuseä¼˜åŒ–](https://zhuanlan.zhihu.com/p/615619524)
- [CodeGeeXç™¾äº¿å‚æ•°å¤§æ¨¡å‹çš„è°ƒä¼˜ç¬”è®°ï¼šæ¯”FasterTransformeræ›´å¿«çš„è§£å†³æ–¹æ¡ˆ](https://zhuanlan.zhihu.com/p/617027615)
- [ã€BBufçš„cudaå­¦ä¹ ç¬”è®°åã€‘Megatron-LMçš„gradient_accumulation_fusionä¼˜åŒ–](https://mp.weixin.qq.com/s/neP8faIXIvj-XlyFjXjWBg)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åï¼ŒLinear Attentionçš„cuda kernelå®ç°è§£æ](https://mp.weixin.qq.com/s/1EPeU5hsOhB7rNAmmXrZRw)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åä¸€ï¼ŒLinear Attentionçš„cuda kernelå®ç°è¡¥æ¡£](https://mp.weixin.qq.com/s/qDVKclf_AvpZ5qb2Obf4aA)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åäºŒï¼ŒLayerNorm/RMSNormçš„é‡è®¡ç®—å®ç°](https://mp.weixin.qq.com/s/G_XvnB4CeEBWTLNefi0Riw)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åä¸‰ï¼ŒOpenAI Triton å…¥é—¨ç¬”è®°ä¸€](https://mp.weixin.qq.com/s/RMR_n1n6nBqpdMl6tdd7pQ)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åå››ï¼ŒOpenAI Tritonå…¥é—¨ç¬”è®°äºŒ](https://mp.weixin.qq.com/s/ZjADeYg5LCyGaLx0chpSZw)
- [ã€BBufçš„CUDAç¬”è®°ã€‘åäº”ï¼ŒOpenAI Tritonå…¥é—¨ç¬”è®°ä¸‰ FusedAttention](https://mp.weixin.qq.com/s/NKShFDrfDGsb0G6PAkUCGw)
- [AI Infraè®ºæ–‡é˜…è¯»ä¹‹é€šè¿‡æ‰“è¡¨å¾—åˆ°è®­ç»ƒå¤§æ¨¡å‹çš„æœ€ä½³å¹¶è¡Œé…ç½®](https://mp.weixin.qq.com/s/D-14J482SFQf-zh-EFa-1w)
- [AI Infraè®ºæ–‡é˜…è¯»ä¹‹å°†æµæ°´çº¿å¹¶è¡Œæ°”æ³¡å‡ ä¹é™åˆ°é›¶ï¼ˆé™„åŸºäºMeagtron-LMçš„ZB-H1å¼€æºä»£ç å®ç°è§£è¯»ï¼‰](https://mp.weixin.qq.com/s/PXjYm9dN8C9B8svMQ7nOvw)
- [AI Infraè®ºæ–‡é˜…è¯»ä¹‹LIGHTSEQï¼ˆLLMé•¿æ–‡æœ¬è®­ç»ƒçš„Infraå·¥ä½œï¼‰](https://mp.weixin.qq.com/s/u4gG1WZ73mgH9mEKQQCRww)
- [AI Infraè®ºæ–‡é˜…è¯»ä¹‹ã€Šåœ¨LLMè®­ç»ƒä¸­å‡å°‘æ¿€æ´»å€¼å†…å­˜ã€‹](https://mp.weixin.qq.com/s/WRUmZT5NIbiHSnNrK1vLOw)
- [ç³»ç»Ÿè°ƒä¼˜åŠ©æ‰‹ï¼ŒPyTorch Profiler TensorBoard æ’ä»¶æ•™ç¨‹](https://mp.weixin.qq.com/s/dG-wlwi8oLg8YMQe_A87qQ)
- [åœ¨GPUä¸ŠåŠ é€ŸRWKV6æ¨¡å‹çš„Linear Attentionè®¡ç®—](https://mp.weixin.qq.com/s/YXtvafdxB1rVeoy0qJmjyA)
- [flash-linear-attentionçš„fused_recurrent_rwkv6 Tritonå®ç°ç²¾è¯»](https://mp.weixin.qq.com/s/H6wWBxwIJNCzkIlH_uIuiw)
- [flash-linear-attentionä¸­çš„Chunkwiseå¹¶è¡Œç®—æ³•çš„ç†è§£](https://mp.weixin.qq.com/s/7utRk157_TFxF8gNRCyIyA)
- [ç¡¬ä»¶é«˜æ•ˆçš„çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶Gated Linear Attentionè®ºæ–‡é˜…è¯»](https://mp.weixin.qq.com/s/IVFeHK1ItPVzttmRRa7ycw)
- [GQAï¼ŒMLAä¹‹å¤–çš„å¦ä¸€ç§KV Cacheå‹ç¼©æ–¹å¼ï¼šåŠ¨æ€å†…å­˜å‹ç¼©ï¼ˆDMCï¼‰](https://mp.weixin.qq.com/s/5pd4fF14ZUgYeM4UXA7ujQ)
- [vAttentionï¼šç”¨äºåœ¨æ²¡æœ‰Paged Attentionçš„æƒ…å†µä¸‹Serving LLM](https://mp.weixin.qq.com/s/F87-Qoo3xYGbwTTYr68guw)
- [å¤§æ¨¡å‹KV CacheèŠ‚çœç¥å™¨MLAå­¦ä¹ ç¬”è®°ï¼ˆåŒ…å«æ¨ç†æ—¶çš„çŸ©é˜µå¸æ”¶åˆ†æï¼‰](https://mp.weixin.qq.com/s/cBMrRUdM1IM0T1ji_ODxng)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬ä¸€è¯¾: å¦‚ä½•åœ¨ PyTorch ä¸­ profile CUDA kernels](https://mp.weixin.qq.com/s/owF7AFR61SLrOosUPdZPQQ)
- [CUDA-MODE ç¬¬ä¸€è¯¾è¯¾åå®æˆ˜ï¼ˆä¸Šï¼‰](https://mp.weixin.qq.com/s/9XeJPWUsKTaMU2OdPkL-OQ)
- [CUDA-MODE ç¬¬ä¸€è¯¾è¯¾åå®æˆ˜ï¼ˆä¸‹ï¼‰](https://mp.weixin.qq.com/s/FCqnQESCQTtlqCG_BSLulA)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬äºŒè¯¾: PMPP ä¹¦çš„ç¬¬1-3ç« é€Ÿé€š](https://mp.weixin.qq.com/s/y0fYn8gUqHqEoRO41ftKnA)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬å››è¯¾: PMPP ä¹¦çš„ç¬¬4-5ç« ç¬”è®°](https://mp.weixin.qq.com/s/P87c8LRJ1CEOOyaQw8L-cA)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬6è¯¾: å¦‚ä½•ä¼˜åŒ–PyTorchä¸­çš„ä¼˜åŒ–å™¨](https://mp.weixin.qq.com/s/qxPYdGZ71DKVLnnYxmvUVA)
- [CUTLASS 2.x & CUTLASS 3.x Intro å­¦ä¹ ç¬”è®°](https://mp.weixin.qq.com/s/r9b1dGyOr82ooMl4LD1n_Q)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬7è¯¾: Quantization Cuda vs Triton](https://mp.weixin.qq.com/s/1gCgpp49NF7sDw__EpO-nw)
- [TRT-LLMä¸­çš„Quantization GEMMï¼ˆAmpere Mixed GEMMï¼‰CUTLASS 2.x è¯¾ç¨‹å­¦ä¹ ç¬”è®°](https://mp.weixin.qq.com/s/NPytrkchX25YRBc_6Zy6nA)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬8è¯¾: CUDAæ€§èƒ½æ£€æŸ¥æ¸…å•](https://mp.weixin.qq.com/s/zJLDVF-yjuZ_lMjaCHoS5g)
- [TensorRT-LLM ä¸­çš„ Hopper Mixed GEMM çš„ CUTLASS 3.x å®ç°è®²è§£](https://mp.weixin.qq.com/s/AntEnjuNqrAnU9pe2rGC6Q)
- [é€šè¿‡å¾®åŸºå‡†æµ‹è¯•å’ŒæŒ‡ä»¤çº§åˆ†æ(Instruction-level Analysis)æ­ç§˜è‹±ä¼Ÿè¾¾Ampereæ¶æ„](https://mp.weixin.qq.com/s/lmy6Drqh0LbomcaA19Nf8Q)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬9è¯¾: å½’çº¦ï¼ˆä¹Ÿå¯¹åº”PMPPçš„ç¬¬10ç« ï¼‰](https://mp.weixin.qq.com/s/jdZEPLIzgKm8hilXIUKUww)
- [ã€ç¿»è¯‘ã€‘Accelerating Llama3 FP8 Inference with Triton Kernels](https://mp.weixin.qq.com/s/v6Ah4uFtI2zTgiAZ3-mKvw)
- [ã€PyTorch å¥‡æ·«æŠ€å·§ã€‘Python Custom Operatorsç¿»è¯‘](https://mp.weixin.qq.com/s/1P5gXcDhQxavsgo2IYP6rQ)
- [ã€ç¿»è¯‘ã€‘æ•™ç¨‹ï¼šåœ¨PyTorchä¸­ä¸ºCUDAåº“ç»‘å®šPythonæ¥å£](https://mp.weixin.qq.com/s/sgFP59OT-Ex2F9zguSr2Rg)
- [ã€ç¿»è¯‘ã€‘æ•™ç¨‹ï¼šCUTLASSä¸­çš„çŸ©é˜µè½¬ç½® (ä½¿ç”¨CuTeæŠŠçŸ©é˜µè½¬ç½®ä¼˜åŒ–åˆ°GPUå†…å­˜å¸¦å®½ä¸Šä¸‹é™)](https://mp.weixin.qq.com/s/IQaD4Cq0SEVjmus1wB4-cg)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬11è¯¾: Sparsity](https://mp.weixin.qq.com/s/28Ku4_EXm0H-ipJX9LKF6g)
- [ã€PyTorch å¥‡æ·«æŠ€å·§ã€‘Async Checkpoint Save](https://mp.weixin.qq.com/s/DcNjBi_rJKvrU9Ssp8Mo0Q)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬12è¯¾ï¼ŒFlash Attention](https://mp.weixin.qq.com/s/IBeBHO5WlS5BfyL0nZaDHg)
- [ã€ç¿»è¯‘ã€‘åœ¨ GPU ä¸Šå¦‚ä½•åŠ é€Ÿ GPTQ Triton åé‡åŒ–kernel](https://mp.weixin.qq.com/s/CX6lPJOVYRPlpFS_WbGbmg)
- [åŸºäºo1-previewè§£è¯» Optimized GPTQ INT4 Dequantization Triton Kernel](https://mp.weixin.qq.com/s/xhCNBjFr6m5hPDPGIhDP7w)
- [ã€ç¿»è¯‘ã€‘æ·±å…¥æ¢è®¨ Hopper TMA å•å…ƒåœ¨ FP8 GEMM è¿ç®—ä¸­çš„åº”ç”¨](https://mp.weixin.qq.com/s/cZRoRq_gzAdA2iaMpZ08VA)
- [ã€ç¿»è¯‘ã€‘CUTLASS æ•™ç¨‹ï¼šæŒæ¡ NVIDIAÂ® å¼ é‡å†…å­˜åŠ é€Ÿå™¨ (TMA)](https://mp.weixin.qq.com/s/0J-JihHhfl77AS2uowA1RA)
- [ã€PyTorch å¥‡æŠ€æ·«å·§ã€‘ä»‹ç» depyfï¼šè½»æ¾æŒæ¡ torch.compile](https://mp.weixin.qq.com/s/Z4VG59ihp_r2H75HLGlMaQ)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬13è¯¾ï¼šRing Attention](https://mp.weixin.qq.com/s/hvqPhNo3l0tL_-lf978euw)
- [ã€ç¿»è¯‘ã€‘torch.compile çš„è¯¦ç»†ç¤ºä¾‹è§£ææ•™ç¨‹](https://mp.weixin.qq.com/s/8FwbaP5q4f_VGWE4vobaMw)
- [ã€ç¿»è¯‘ã€‘ã€PyTorch å¥‡æŠ€æ·«å·§ã€‘FlexAttetion åŸºäºTritonæ‰“é€ çµæ´»åº¦æ‹‰æ»¡çš„Attention](https://mp.weixin.qq.com/s/KJUk-jmwGPrJvVuLQ44DyQ)
- [Flex Attention API åº”ç”¨ Notebook ä»£ç é€Ÿè§ˆ](https://mp.weixin.qq.com/s/ufOKYJn6z19MreiEk0YAEA)
- [ã€ç¿»è¯‘ã€‘CUDA-Free Inference for LLMs](https://mp.weixin.qq.com/s/KlxBzBNxyRBnoEr8qXjgeg)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬14è¯¾ï¼ŒTriton å®è·µæŒ‡å—](https://mp.weixin.qq.com/s/bWn4epnUAkHc-7nQGJjpyw)
- [ã€ç¿»è¯‘ã€‘ä½¿ç”¨PyTorch FSDPæœ€å¤§åŒ–è®­ç»ƒååé‡](https://mp.weixin.qq.com/s/6wNX38rKcFjxLb4ooYQokw)
- [ã€ç¿»è¯‘ã€‘ä½¿ç”¨PyTorch FSDPå’ŒTorch.compileæœ€å¤§åŒ–è®­ç»ƒååé‡](https://mp.weixin.qq.com/s/YVVau7boVUEnVB6o_qKORA)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘å¤§æ¨¡å‹æ¨ç†](https://mp.weixin.qq.com/s/9417IxdvNMYThjmaSwPBTw)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘AIç³»ç»Ÿä¸­çš„ç½‘ç»œæ¦‚è¿°](https://mp.weixin.qq.com/s/dhspQMOHerIpKESb4IWCgg)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘AIç³»ç»Ÿä¸­çš„ç½‘ç»œ debug](https://mp.weixin.qq.com/s/sne7cjEnzzSW_5bsAn-P3A)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘AIç³»ç»Ÿä¸­çš„ç½‘ç»œ benchmark](https://mp.weixin.qq.com/s/FlSkBykNIFXfc6TnqOX25A)
- [ã€ç¿»è¯‘ã€‘åœ¨FSDP2ä¸­å¼€å¯Float8 All-Gather](https://mp.weixin.qq.com/s/44zFNWr5aVtA3zPtegY9dg)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘è®­ç»ƒä¹‹æ¨¡å‹å¹¶è¡Œ](https://mp.weixin.qq.com/s/VTrTM121jEPGEuFaeIT4Cw)
- [æ¢³ç†ä¸‹Flash Attentionçš„dispatché€»è¾‘](https://mp.weixin.qq.com/s/Dcw0F4HpV33Uziy2lvNUeA)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘è®¡ç®—åŠ é€Ÿå™¨ä¹‹cpu](https://mp.weixin.qq.com/s/IQd4lz8ebQTrkj_lwDXuSA)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° Lecture 16 é€šè¿‡CUDA C++æ ¸å¿ƒåº“æŠŠllm.cç§»æ¤ä¸ºllm.cpp](https://mp.weixin.qq.com/s/ynJwHLH9LFKNBYBBWgU25A)
- [GPU çŸ©é˜µä¹˜å®é™…å¯è¾¾æœ€å¤§FLOPSæµ‹é‡å·¥å…·](https://mp.weixin.qq.com/s/kkIxIUaKtSECMNcvma_ayg)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬28è¯¾ ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„LinkedIn Liger kernel](https://mp.weixin.qq.com/s/Mcmii9XYR7zw2H_DA8IUUQ)
- [RMSNormçš„ç²¾åº¦é™·é˜±ï¼šè®°ä¸€æ¬¡LLMæ¨ç†ç²¾åº¦è°ƒæŸ¥](https://mp.weixin.qq.com/s/Jag-WRH_2w5-GjTYbRnb-Q)
- [å¦‚ä½•æ­£ç¡®ç†è§£NVIDIA GPUåˆ©ç”¨ç‡çš„æ¦‚å¿µ ](https://mp.weixin.qq.com/s/sYJvdqB9PGhEJphMkuSOzw)
- [CUDA-MODE è¯¾ç¨‹ç¬”è®° ç¬¬29è¯¾ Tritonå†…éƒ¨æœºåˆ¶](https://mp.weixin.qq.com/s/7tfTXaG7D208l_5DzN9hBw)
- [GTX 4090 çš„ cuda graph è¯¡å¼‚](https://mp.weixin.qq.com/s/SAfnlT4aTd67sRqOAoCxQg)
- [ã€ml-engineering ç¿»è¯‘ç³»åˆ—ã€‘è®¡ç®—åŠ é€Ÿå™¨ä¹‹gpu](https://mp.weixin.qq.com/s/1B52ORme3s2gzpXPXGNNQw)
- [CUDA-MODEè¯¾ç¨‹ç¬”è®° ç¬¬17è¯¾ GPUé›†åˆé€šä¿¡(NCCL)](https://mp.weixin.qq.com/s/1QdEJKs4a4u3BepNQ716cQ)
- [Triton Kernel ç¼–è¯‘é˜¶æ®µ](https://mp.weixin.qq.com/s/dw9bP1ZI__0yrf2_wb6nag)
- [ä½¿ç”¨torchtuneæŠŠLLaMa-3.1 8Bè’¸é¦ä¸º1B](https://mp.weixin.qq.com/s/TfH9tqNjIdNiIi9iwSdY7w)
- [[åˆ†å¸ƒå¼è®­ç»ƒä¸TorchTitan] PyTorchä¸­çš„Async Tensor Parallelismä»‹ç»](https://mp.weixin.qq.com/s/Jx4B-sF9dudg7OOT-FbsLg)
- [PyTorch åšå®¢ CUTLASS Ping-Pong GEMM Kernel ç®€ä»‹](https://mp.weixin.qq.com/s/QWS9YEjsbM7hzy5tJm--1g)
- [PyTorchåšå®¢ ã€Šä½¿ç”¨ Triton åŠ é€Ÿ 2D åŠ¨æ€å—é‡åŒ– Float8 GEMM ç®€ä»‹ã€‹](https://mp.weixin.qq.com/s/oK45nVPTctIHW-rXbJ128Q)
- [ä½¿ç”¨NCUå’ŒCursor Claude-sonnet-3.5å†™å‡ºé«˜æ•ˆcudaç®—å­çš„æ­£ç¡®å§¿åŠ¿](https://mp.weixin.qq.com/s/YEw8JZxn15CfLEnK32Jj-Q)
- [Fused AllGather_MatMul Tritonå·¥ç¨‹å®ç°](https://mp.weixin.qq.com/s/oMkyrelpXjc3-KUQBVx6Tg)
- [MoEä¹‹å¹´çš„æ€»ç»“å’ŒMoE æ¨ç†ä¼˜åŒ–çš„ä¸€äº›è®¤è¯†](https://mp.weixin.qq.com/s/RXFmnVI_JIlT0Yo6bN3ZHg)
- [SGLang DP MLA ç‰¹æ€§è§£è¯»](https://mp.weixin.qq.com/s/X2uA507VbQVCv3JIQ8EtPA)
- [Windsurfï¼ˆå¯å¹³æ›¿ Cursorï¼‰ çš„ä½¿ç”¨ä½“éªŒå’ŒæŠ€å·§](https://mp.weixin.qq.com/s/3PNaEom76jQ8bdxNtYWkkA)
- [SGLang MLA å®ç°è§£æ](https://mp.weixin.qq.com/s/wRIjy_HHAH_CeEhkZ_BvNg)
- [è¯¦è§£vLLMå’ŒSGLang awq dequantize kernelçš„é­”æ³•](https://mp.weixin.qq.com/s/X9AOH1HGXJ3t0jZ5_hd7Ew)

</details>

### 21. CUDA/å¤§æ¨¡å‹ å­¦ä¹ èµ„æ–™æ”¶é›†

#### ä¸“æ 

- [CUDAç¼–ç¨‹å…¥é—¨åŠä¼˜åŒ– ä¸“æ by jie.hang](https://www.zhihu.com/column/c_1522503697624346624)
- [æ·±å…¥æµ…å‡ºGPUä¼˜åŒ– ä¸“æ by æœ‰äº†ç¦ç¦çš„æ£å­](https://www.zhihu.com/column/c_1437330196193640448)
- [CUDA ç¼–ç¨‹å…¥é—¨](https://www.zhihu.com/column/c_1699097150611595264)

#### CUDA ç›¸å…³åšå®¢

<details>
<summary>ç‚¹å‡»å±•å¼€/æ”¶èµ· CUDAä¼˜è´¨åšå®¢åˆ—è¡¨</summary>

- [ä¸€æ–‡è¯»æ‡‚nvidia-smi topoçš„è¾“å‡º](https://zhuanlan.zhihu.com/p/692947173)
- [å¦‚æœä½ æ˜¯ä¸€ä¸ªC++é¢è¯•å®˜ï¼Œä½ ä¼šé—®å“ªäº›é—®é¢˜ï¼Ÿ](https://www.zhihu.com/question/451327108/answer/3299498791)
- [æ¨ç†éƒ¨ç½²å·¥ç¨‹å¸ˆé¢è¯•é¢˜åº“](https://zhuanlan.zhihu.com/p/673046520)
- [[C++ç‰¹æ€§]å¯¹std::moveå’Œstd::forwardçš„ç†è§£](https://zhuanlan.zhihu.com/p/469607144)
- [è®ºæ–‡é˜…è¯»ï¼šMimalloc Free List Sharding in Action](https://zhuanlan.zhihu.com/p/665602526)
- [åœ¨ C++ ä¸­ï¼ŒRAII æœ‰å“ªäº›å¦™ç”¨ï¼Ÿ](https://zhuanlan.zhihu.com/p/687230917)
- [AI/HPCé¢è¯•é—®é¢˜æ•´ç†](https://zhuanlan.zhihu.com/p/663917237)
- [Roofline Modelä¸æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½åˆ†æ](https://zhuanlan.zhihu.com/p/34204282)
- [FlashAttentionæ ¸å¿ƒé€»è¾‘ä»¥åŠV1 V2å·®å¼‚æ€»ç»“](https://zhuanlan.zhihu.com/p/665170554)
- [flash attention 1å’Œflash attention 2ç®—æ³•çš„pythonå’Œtritonå®ç°](https://zhuanlan.zhihu.com/p/662759306)
- [Flash Attention æ¨å…¬å¼](https://zhuanlan.zhihu.com/p/646697716)
- [å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlashAttention V1ï¼Œä»ç¡¬ä»¶åˆ°è®¡ç®—é€»è¾‘](https://zhuanlan.zhihu.com/p/669926191)
- [flash attentionå®Œå…¨è§£æå’ŒCUDAé›¶åŸºç¡€å®ç°](https://zhuanlan.zhihu.com/p/658947627)
- [FlashAttentionå›¾è§£ï¼ˆå¦‚ä½•åŠ é€ŸAttentionï¼‰](https://zhuanlan.zhihu.com/p/626079753)
- [FlashAttention:åŠ é€Ÿè®¡ç®—,èŠ‚çœæ˜¾å­˜, IOæ„ŸçŸ¥çš„ç²¾ç¡®æ³¨æ„åŠ›](https://zhuanlan.zhihu.com/p/639228219)
- [FlashAttention åå‘ä¼ æ’­è¿ç®—æ¨å¯¼](https://zhuanlan.zhihu.com/p/631106302)
- [æ¯”æ ‡å‡†Attentionæé€Ÿ5-9å€ï¼Œå¤§æ¨¡å‹éƒ½åœ¨ç”¨çš„FlashAttention v2æ¥äº†](https://zhuanlan.zhihu.com/p/644324647)
- [FlashAttention çš„é€Ÿåº¦ä¼˜åŒ–åŸç†æ˜¯æ€æ ·çš„ï¼Ÿ](https://www.zhihu.com/question/611236756/answer/3134408839)
- [FlashAttention çš„é€Ÿåº¦ä¼˜åŒ–åŸç†æ˜¯æ€æ ·çš„ï¼Ÿ](https://www.zhihu.com/question/611236756/answer/3132304304)
- [FlashAttention2è¯¦è§£ï¼ˆæ€§èƒ½æ¯”FlashAttentionæå‡200%ï¼‰](https://zhuanlan.zhihu.com/p/645376942)
- [FlashAttenion-V3: Flash Decodingè¯¦è§£](https://zhuanlan.zhihu.com/p/661478232)
- [é€Ÿé€šPageAttention2](https://zhuanlan.zhihu.com/p/671293276)
- [PageAttentionä»£ç èµ°è¯»](https://zhuanlan.zhihu.com/p/668736097)
- [å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿä¹‹FlashDecoding++ï¼šé‡ç”ŸFlashæŠµè¾¾æˆ˜åœº](https://zhuanlan.zhihu.com/p/665361668)
- [å­¦ä¹ Flash Attentionå’ŒFlash Decodingçš„ä¸€äº›æ€è€ƒä¸ç–‘æƒ‘](https://zhuanlan.zhihu.com/p/664704050)
- [å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿä¹‹Flash Decodingï¼šæ›´å°å­ä»»åŠ¡æå‡å¹¶è¡Œåº¦](https://zhuanlan.zhihu.com/p/664264445)
- [FlashAttentionä¸Multi Query Attention](https://zhuanlan.zhihu.com/p/640312259)
- [åŠ¨æ‰‹Attentionä¼˜åŒ–1ï¼šFlash Attention 2ä¼˜åŒ–ç‚¹è§£æ](https://zhuanlan.zhihu.com/p/634427617)
- [Flash Attentionæ¨ç†æ€§èƒ½æ¢ç©¶](https://zhuanlan.zhihu.com/p/652691133)
- [è®°å½•Flash Attention2-å¯¹1åœ¨GPUå¹¶è¡Œæ€§å’Œè®¡ç®—é‡ä¸Šçš„ä¸€äº›å°ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/650947918)
- [[LLM] FlashAttention åŠ é€Ÿattentionè®¡ç®—[ç†è®ºè¯æ˜ï½œä»£ç è§£è¯»]](https://zhuanlan.zhihu.com/p/646084771)
- [FlashAttentionæ ¸å¿ƒé€»è¾‘ä»¥åŠV1 V2å·®å¼‚æ€»ç»“](https://zhuanlan.zhihu.com/p/665170554)
- [ã€æ‰‹æ’•LLM-FlashAttentionã€‘ä»softmaxè¯´èµ·ï¼Œä¿å§†çº§è¶…é•¿æ–‡ï¼ï¼](https://zhuanlan.zhihu.com/p/663932651)
- [åŠ¨æ‰‹Attentionä¼˜åŒ–2ï¼šå›¾è§£åŸºäºPTXçš„Tensor CoreçŸ©é˜µåˆ†å—ä¹˜æ³•å®ç°](https://zhuanlan.zhihu.com/p/650374808)
- [flash attention çš„å‡ ä¸ªè¦ç‚¹](https://zhuanlan.zhihu.com/p/663381513)
- [GPUå†…å­˜(æ˜¾å­˜)çš„ç†è§£ä¸åŸºæœ¬ä½¿ç”¨](https://zhuanlan.zhihu.com/p/462191421)
- [å›¾æ–‡å¹¶èŒ‚ï¼Œè¶…è¯¦ç»†è§£è¯»nms cudaæ‹“å±•æºç ](https://zhuanlan.zhihu.com/p/466169614)
- [å¤§æ¨¡å‹çš„å¥½ä¼™ä¼´ï¼Œæµ…ææ¨ç†åŠ é€Ÿå¼•æ“FasterTransformer](https://zhuanlan.zhihu.com/p/626008090)
- [LLM Inference CookBookï¼ˆæŒç»­æ›´æ–°ï¼‰](https://zhuanlan.zhihu.com/p/619596323)
- [NVIDIAçš„custom allreduce](https://zhuanlan.zhihu.com/p/611229620)
- [[è®ºæ–‡é€Ÿè¯»] FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://zhuanlan.zhihu.com/p/548811565)
- [CUDAéšç¬”ä¹‹Streamçš„ä½¿ç”¨](https://zhuanlan.zhihu.com/p/51402722)
- [ç®€å•è¯»è¯»FasterTransformer](https://zhuanlan.zhihu.com/p/589442432)
- [cutlass FusedMultiheadAttentionä»£ç è§£è¯»](https://zhuanlan.zhihu.com/p/600373700)
- [ç®€å•è°ˆè°ˆCUDA Reduce](https://zhuanlan.zhihu.com/p/559549740)
- [GridReduce - CUDA Reduce éƒ¨åˆ†ç»“æœå½’çº¦](https://zhuanlan.zhihu.com/p/635456406)
- [CUTLASS: Fast Linear Algebra in CUDA C++](https://zhuanlan.zhihu.com/p/461060382)
- [cutlassæºç å¯¼è¯»ï¼ˆ1ï¼‰â€”â€”APIä¸è®¾è®¡ç†å¿µ](https://zhuanlan.zhihu.com/p/588953452)
- [cutlassæºç å¯¼è¯»ï¼ˆ2ï¼‰â€”â€”Gemmçš„è®¡ç®—æµç¨‹](https://zhuanlan.zhihu.com/p/592689326)
- [CUDA GroupNorm NHWCä¼˜åŒ–](https://zhuanlan.zhihu.com/p/596871310)
- [ä¼ ç»Ÿ CUDA GEMM ä¸å®Œå…¨æŒ‡åŒ—](https://zhuanlan.zhihu.com/p/584236348)
- [æ€ä¹ˆè¯„ä¼°å†…å­˜å¸¦å®½çš„æŒ‡æ ‡ï¼Œå¹¶è¿›è¡Œä¼˜åŒ–?](https://www.zhihu.com/question/424477202/answer/2322341112)
- [TensorRT Diffusionæ¨¡å‹ä¼˜åŒ–ç‚¹](https://zhuanlan.zhihu.com/p/592713879)
- [NVIDIA GPUæ€§èƒ½ä¼˜åŒ–åŸºç¡€](https://zhuanlan.zhihu.com/p/577412348)
- [ä¸€æ–‡ç†è§£ PyTorch ä¸­çš„ SyncBatchNorm](https://zhuanlan.zhihu.com/p/555881100)
- [å¦‚ä½•å¼€å‘æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼šé«˜æ€§èƒ½GPUçŸ©é˜µä¹˜æ³•](https://zhuanlan.zhihu.com/p/531498210)
- [CUDA SGEMMçŸ©é˜µä¹˜æ³•ä¼˜åŒ–ç¬”è®°â€”â€”ä»å…¥é—¨åˆ°cublas](https://zhuanlan.zhihu.com/p/518857175)
- [Dropoutç®—å­çš„bitmaskä¼˜åŒ–](https://zhuanlan.zhihu.com/p/517766170)
- [é¢å‘ Tensor Core çš„ç®—å­è‡ªåŠ¨ç”Ÿæˆ](https://zhuanlan.zhihu.com/p/502935328)
- [PICASSOè®ºæ–‡å­¦ä¹ ](https://zhuanlan.zhihu.com/p/500026086)
- [CUDAç¿»è¯‘ï¼šHow to Access Global Memory Efficiently in CUDA C/C++ Kernels](https://zhuanlan.zhihu.com/p/473133201)
- [CUDA Pro Tipsç¿»è¯‘ï¼šWrite Flexible Kernels with Grid-Stride Loops](https://zhuanlan.zhihu.com/p/472952257)
- [[æ–½å·¥ä¸­] CUDA GEMM ç†è®ºæ€§èƒ½åˆ†æä¸ kernel ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/441146275)
- [CUDA Ampere Tensor Core HGEMM çŸ©é˜µä¹˜æ³•ä¼˜åŒ–ç¬”è®° â€”â€” Up To 131 TFLOPS!](https://zhuanlan.zhihu.com/p/555339335)
- [Nvidia Tensor Core-CUDA HGEMMä¼˜åŒ–è¿›é˜¶](https://zhuanlan.zhihu.com/p/639297098)
- [CUDA C++ Best Practices Guide Release 12.1ç¬”è®°ï¼ˆä¸€ï¼‰](https://zhuanlan.zhihu.com/p/636103380)
- [CUDA çŸ©é˜µä¹˜æ³•ç»ˆæä¼˜åŒ–æŒ‡å—](https://zhuanlan.zhihu.com/p/410278370)
- [å¦‚ä½•ç”¨CUDAå†™æœ‰CuBLAS 90%æ€§èƒ½çš„GEMM Kernel](https://zhuanlan.zhihu.com/p/631227862)
- [å¦‚ä½•ç†è§£Nvidiaè‹±ä¼Ÿè¾¾çš„Multi-GPUå¤šå¡é€šä¿¡æ¡†æ¶NCCLï¼Ÿ](https://www.zhihu.com/question/63219175/answer/2768301153)
- [å¦‚ä½•ç†è§£Nvidiaè‹±ä¼Ÿè¾¾çš„Multi-GPUå¤šå¡é€šä¿¡æ¡†æ¶NCCLï¼Ÿ](https://www.zhihu.com/question/63219175/answer/206697974)
- [å¦‚ä½•ç†è§£Nvidiaè‹±ä¼Ÿè¾¾çš„Multi-GPUå¤šå¡é€šä¿¡æ¡†æ¶NCCLï¼Ÿ](https://www.zhihu.com/question/63219175/answer/3487108775)
- [ä½¿ç”¨FasterTransformerå®ç°LLMåˆ†å¸ƒå¼æ¨ç†](https://zhuanlan.zhihu.com/p/644322962)
- [ç»†ç²’åº¦GPUçŸ¥è¯†ç‚¹è¯¦ç»†æ€»ç»“](https://zhuanlan.zhihu.com/p/349185459)
- [https://siboehm.com/articles/22/CUDA-MMM](https://siboehm.com/articles/22/CUDA-MMM)
- [ã€CUDAç¼–ç¨‹ã€‘OneFlow Softmaxç®—å­æºç è§£è¯»ä¹‹BlockSoftmax](https://zhuanlan.zhihu.com/p/646998408)
- [ã€CUDAç¼–ç¨‹ã€‘OneFlow Softmax ç®—å­æºç è§£è¯»ä¹‹WarpSoftmax](https://zhuanlan.zhihu.com/p/646994689)
- [ã€CUDAç¼–ç¨‹ã€‘OneFlow Element-Wise ç®—å­æºç è§£è¯»](https://zhuanlan.zhihu.com/p/646990764)
- [ã€CUDAç¼–ç¨‹ã€‘Faster Transformer v1.0 æºç è¯¦è§£](https://zhuanlan.zhihu.com/p/647012855)
- [ã€CUDAç¼–ç¨‹ã€‘Faster Transformer v2.0 æºç è¯¦è§£](https://zhuanlan.zhihu.com/p/650462095)
- [FasterTransformer Decoding æºç åˆ†æ(ä¸ƒ)-FFNLayer MoE(ä¸Šç¯‡)](https://zhuanlan.zhihu.com/p/670916589)
- [FasterTransformer Decoding æºç åˆ†æ(å…«)-FFNLayer MoE(ä¸‹ç¯‡)](https://zhuanlan.zhihu.com/p/672189305)
- [ä»rooflineæ¨¡å‹çœ‹CPUçŸ©é˜µä¹˜æ³•ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/655421318)
- [æ€§èƒ½ä¼˜åŒ–çš„ç»ˆææ‰‹æ®µä¹‹ Profile-Guided Optimization (PGO)](https://zhuanlan.zhihu.com/p/652814504)
- [æœ‰æ²¡æœ‰å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿå¼•æ“FasterTransformerå…¥é—¨çº§æ•™ç¨‹ï¼Ÿ](https://www.zhihu.com/question/602468960/answer/3203088852)
- [æ·±å…¥æµ…å‡ºGPUä¼˜åŒ–ç³»åˆ—ï¼šgemvä¼˜åŒ–](https://zhuanlan.zhihu.com/p/494144694)
- [NVIDIA Hopperæ¶æ„TensorCoreåˆ†æ(4)](https://zhuanlan.zhihu.com/p/654067822)
- [GPU host+deviceçš„ç¼–è¯‘æµç¨‹](https://zhuanlan.zhihu.com/p/655850951)
- [Tensor Core ä¼˜åŒ–åŠç²¾åº¦çŸ©é˜µä¹˜æ­ç§˜](https://zhuanlan.zhihu.com/p/658306956)
- [æ— ç—›CUDAå®è·µï¼šÎ¼-CUDA è‡ªåŠ¨è®¡ç®—å›¾ç”Ÿæˆ](https://zhuanlan.zhihu.com/p/658080362)
- [CUDAï¼ˆä¸‰ï¼‰ï¼šé€šç”¨çŸ©é˜µä¹˜æ³•ï¼šä»å…¥é—¨åˆ°ç†Ÿç»ƒ](https://zhuanlan.zhihu.com/p/657632577)
- [è‡ªå·±å†™çš„CUDAçŸ©é˜µä¹˜æ³•èƒ½ä¼˜åŒ–åˆ°å¤šå¿«ï¼Ÿ](https://www.zhihu.com/question/41060378/answer/2645323107)
- [é«˜æ•ˆCUDA Scanç®—æ³•æµ…æ](https://zhuanlan.zhihu.com/p/499963645)
- [ä¸€æ¬¡ CUDA Graph è°ƒè¯•ç»å†](https://zhuanlan.zhihu.com/p/661451140)
- [CUDAä¸­çš„radix sortç®—æ³•](https://zhuanlan.zhihu.com/p/488016994)
- [NVIDIA Tensor Coreå¾®æ¶æ„è§£æ](https://zhuanlan.zhihu.com/p/660531822)
- [cutlass cute 101](https://zhuanlan.zhihu.com/p/660379052)
- [åœ¨GPUé¿å…åˆ†æ”¯çš„æ–¹æ³•](https://zhuanlan.zhihu.com/p/143571980)
- [Pytorch-CUDAä»å…¥é—¨åˆ°æ”¾å¼ƒï¼ˆäºŒï¼‰](https://zhuanlan.zhihu.com/p/48463543)
- [è…¾è®¯æœºæ™ºå›¢é˜Ÿåˆ†äº«--AllReduceç®—æ³•çš„å‰ä¸–ä»Šç”Ÿ](https://zhuanlan.zhihu.com/p/79030485)
- [cute ä¹‹ Layout](https://zhuanlan.zhihu.com/p/661182311)
- [cute Layout çš„ä»£æ•°å’Œå‡ ä½•è§£é‡Š](https://zhuanlan.zhihu.com/p/662089556)
- [cute ä¹‹ GEMMæµæ°´çº¿](https://zhuanlan.zhihu.com/p/665082713)
- [Using CUDA Warp-Level Primitives](https://zhuanlan.zhihu.com/p/664395938)
- [CUDA Pro Tip: Increase Performance with Vectorized Memory Access](https://zhuanlan.zhihu.com/p/666480387)
- [cute ä¹‹ ç®€å•GEMMå®ç°](https://zhuanlan.zhihu.com/p/667521327)
- [cute ä¹‹ MMAæŠ½è±¡](https://zhuanlan.zhihu.com/p/663092747)
- [cute ä¹‹ Tensor](https://zhuanlan.zhihu.com/p/663093816)
- [cute Swizzleç»†è°ˆ](https://zhuanlan.zhihu.com/p/684250988)
- [åŸºäº CUTE çš„ GEMM ä¼˜åŒ–ã€2ã€‘â€”â€” é«˜æ•ˆ GEMM å®ç°ï¼Œè¶…è¶Š Cublas 20%](https://zhuanlan.zhihu.com/p/696028389)
- [CUDAå•ç²¾åº¦çŸ©é˜µä¹˜æ³•(sgemm)ä¼˜åŒ–ç¬”è®°](https://zhuanlan.zhihu.com/p/638820727)
- [HPCï¼ˆé«˜æ€§èƒ½è®¡ç®—ç¬¬ä¸€ç¯‡ï¼‰ ï¼šä¸€æ–‡å½»åº•ææ‡‚å¹¶å‘ç¼–ç¨‹ä¸å†…å­˜å±éšœï¼ˆç¬¬ä¸€ç¯‡ï¼‰](https://zhuanlan.zhihu.com/p/670350655)
- [GPU CUDA ç¼–ç¨‹çš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆ? æ€ä¹ˆå…¥é—¨?](https://www.zhihu.com/question/613405221/answer/3129776636)
- [å¦‚ä½•å…¥é—¨ OpenAI Triton ç¼–ç¨‹?](https://www.zhihu.com/question/622685131/answer/3217107882)
- [CUDAï¼ˆäºŒï¼‰ï¼šGPUçš„å†…å­˜ä½“ç³»åŠå…¶ä¼˜åŒ–æŒ‡å—](https://zhuanlan.zhihu.com/p/654027980)
- [nvitop: å²ä¸Šæœ€å¼ºGPUæ€§èƒ½å®æ—¶ç›‘æµ‹å·¥å…·](https://zhuanlan.zhihu.com/p/614024375)
- [ä½¿ç”¨Tritonåœ¨æ¨¡å‹ä¸­æ„å»ºè‡ªå®šä¹‰ç®—å­](https://zhuanlan.zhihu.com/p/670326958)
- [CUDAç¬”è®° å†…å­˜åˆå¹¶è®¿é—®](https://zhuanlan.zhihu.com/p/641639133)
- [GPGPUæ¶æ„ï¼Œç¼–è¯‘å™¨å’Œè¿è¡Œæ—¶](https://zhuanlan.zhihu.com/p/592975749)
- [GPGPUçš„memory ä½“ç³»ç†è§£](https://zhuanlan.zhihu.com/p/658081469)
- [nvlinké‚£äº›äº‹â€¦â€¦](https://zhuanlan.zhihu.com/p/639228770)
- [å¯¹NVidia Hopper GH100 çš„ä¸€äº›ç†è§£](https://zhuanlan.zhihu.com/p/486224812)
- [é»‘ç§‘æŠ€ï¼šç”¨cutlassè¿›è¡Œä½æˆæœ¬ã€é«˜æ€§èƒ½å·ç§¯ç®—å­å®šåˆ¶å¼€å‘](https://zhuanlan.zhihu.com/p/258931422)
- [ä¹±è°ˆTriton Ampere WMMA (æ–½å·¥ä¸­)](https://zhuanlan.zhihu.com/p/675925978)
- [å¯èƒ½æ˜¯è®²çš„æœ€æ¸…æ¥šçš„WeightonlyGEMMåšå®¢](https://zhuanlan.zhihu.com/p/675427125)
- [GPU åº•å±‚æœºåˆ¶åˆ†æï¼škernel launch å¼€é”€](https://zhuanlan.zhihu.com/p/544492099)
- [GPUå†…å­˜(æ˜¾å­˜)çš„ç†è§£ä¸åŸºæœ¬ä½¿ç”¨](https://zhuanlan.zhihu.com/p/462191421)
- [è¶…è¶ŠAITemplateï¼Œæ‰“å¹³TensorRTï¼ŒSDå…¨ç³»åˆ—æ¨¡å‹åŠ é€Ÿæ¡†æ¶stable-fastéš†é‡ç™»åœº](https://zhuanlan.zhihu.com/p/669610362)
- [[æ‰‹æŠŠæ‰‹å¸¦ä½ å…¥é—¨CUTLASSç³»åˆ—] 0x00 cutlassåŸºæœ¬è®¤çŸ¥---ä¸ºä»€ä¹ˆè¦ç”¨cutlass](https://zhuanlan.zhihu.com/p/677616101)
- [[æ‰‹æŠŠæ‰‹å¸¦ä½ å…¥é—¨CUTLASSç³»åˆ—] 0x02 cutlass æºç åˆ†æ(ä¸€) --- block swizzle å’Œ tile iterator (é™„tvmç­‰ä»·code)](https://zhuanlan.zhihu.com/p/679929705)
- [[æ‰‹æŠŠæ‰‹å¸¦ä½ å…¥é—¨CUTLASSç³»åˆ—] 0x03 cutlass æºç åˆ†æ(äºŒ) --- bank conflict free çš„shared memory layout (é™„tvmç­‰ä»·pass)](https://zhuanlan.zhihu.com/p/681966685)
- [[æ·±å…¥åˆ†æCUTLASSç³»åˆ—] 0x04 cutlass æºç åˆ†æ(ä¸‰) --- å¤šçº§æµæ°´çº¿(software pipeline)](https://zhuanlan.zhihu.com/p/687397095)
- [[æ·±å…¥åˆ†æCUTLASSç³»åˆ—] 0x03 cutlass æºç åˆ†æ(äºŒ) --- bank conflict free çš„shared memory layout (é™„tvmç­‰ä»·pass)](https://zhuanlan.zhihu.com/p/681966685)
- [GPU å†…å­˜æ¦‚å¿µæµ…æ](https://zhuanlan.zhihu.com/p/651179378)
- [NV_GPU tensor core ç®—åŠ›/å¸¦å®½/ç¼–ç¨‹æ¨¡å‹åˆ†æ](https://zhuanlan.zhihu.com/p/638129792)
- [Nsight Compute - Scheduler Statistics](https://zhuanlan.zhihu.com/p/673770855)
- [NVidia GPUæŒ‡ä»¤é›†æ¶æ„-å‰è¨€](https://zhuanlan.zhihu.com/p/686198447)
- [ææ‡‚ CUDA Shared Memory ä¸Šçš„ bank conflicts å’Œå‘é‡åŒ–æŒ‡ä»¤ï¼ˆLDS.128 / float4ï¼‰çš„è®¿å­˜ç‰¹ç‚¹](https://zhuanlan.zhihu.com/p/690052715)
- [çª¥æ¢Tritionçš„lower(äºŒ)](https://zhuanlan.zhihu.com/p/695255185)
- [çª¥æ¢Tritionçš„lower(ä¸‰)](https://zhuanlan.zhihu.com/p/696133729)
- [ops(2)ï¼šSoftMax ç®—å­çš„ CUDA å®ç°ä¸ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/695307283)
- [cudaå­¦ä¹ æ—¥è®°(6) nsight system / nsight compute](https://zhuanlan.zhihu.com/p/640344249)
- [ops(3)ï¼šCross Entropy çš„ CUDA å®ç°](https://zhuanlan.zhihu.com/p/695594396)
- [cudaçš„ldmatrixæŒ‡ä»¤çš„è¯¦ç»†è§£é‡Š](https://zhuanlan.zhihu.com/p/697228676)
- [æ­ç§˜ Tensor Core åº•å±‚ï¼šå¦‚ä½•è®©AIè®¡ç®—é€Ÿåº¦é£è·ƒ](https://mp.weixin.qq.com/s/UL7CLWp3cmdUgGILr4iVzA)
- [NCCLï¼ˆNVIDIA Collective Communication Libraryï¼‰çš„æ¥é¾™å»è„‰](https://zhuanlan.zhihu.com/p/667221519)
- [ldmatrixä¸swizzleï¼ˆç¬”è®°ï¼‰](https://zhuanlan.zhihu.com/p/696231622)
- [GPUä¸ŠGEMMçš„è¾¹ç•Œé—®é¢˜ä»¥åŠä¼˜åŒ–](https://zhuanlan.zhihu.com/p/699776368)
- [NV Tensor Core and Memory Accelerator ç†è®ºåˆ†æ](https://zhuanlan.zhihu.com/p/601204275)
- [CUTLASS CuTe GEMMç»†èŠ‚åˆ†æï¼ˆä¸€ï¼‰â€”â€”ldmatrixçš„é€‰æ‹©](https://zhuanlan.zhihu.com/p/702818267)
- [Tritonåˆ°PTXï¼ˆ1ï¼‰ï¼šElementwise](https://zhuanlan.zhihu.com/p/699979345)
- [ç”±çŸ©é˜µä¹˜æ³•è¾¹ç•Œå¤„ç†å¼•èµ·çš„CUDA wmma fragmentä¸åŸå§‹çŸ©é˜µå…ƒç´ å¯¹åº”å…³ç³»æ¢ç©¶](https://zhuanlan.zhihu.com/p/703476975)
- [NVIDIA Hopperæ¶æ„TensorCoreåˆ†æ(4)](https://zhuanlan.zhihu.com/p/654067822)
- [NVidia GPUæŒ‡ä»¤é›†æ¶æ„-Loadå’ŒCache](https://zhuanlan.zhihu.com/p/692445145)
- [NVidia GPUæŒ‡ä»¤é›†æ¶æ„-å¯„å­˜å™¨](https://zhuanlan.zhihu.com/p/688616037)
- [Async Copy åŠ Memory Barrier æŒ‡ä»¤çš„åŠŸèƒ½ä¸å®ç°](https://zhuanlan.zhihu.com/p/685168850)
- [tensorcoreä¸­ldmatrixæŒ‡ä»¤çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ](https://www.zhihu.com/question/600927104/answer/3029266372)
- [ä½¿ç”¨cutlass cuteå¤ç°flash attention](https://zhuanlan.zhihu.com/p/696323042)
- [1. CudaçŸ©é˜µä¹˜æ³•GeMMæ€§èƒ½ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/593462636)
- [ä¸€æ­¥æ­¥ä¼˜åŒ– GEMM by Tensorcore](https://zhuanlan.zhihu.com/p/638522893)
- [CUTLASS 3.x å¼‚æ„ç¼–ç¨‹éšæ„Ÿ](https://zhuanlan.zhihu.com/p/689829403)
- [Tritonåˆ°PTXï¼ˆ1ï¼‰ï¼šElementwise](https://zhuanlan.zhihu.com/p/699979345)
- [Tritonåˆ°SASSï¼ˆ2ï¼‰ï¼šReduction](https://zhuanlan.zhihu.com/p/703748336)
- [cudaçš„ldmatrixæŒ‡ä»¤çš„è¯¦ç»†è§£é‡Š](https://zhuanlan.zhihu.com/p/697228676)
- [åŸºäº CuTe ç†è§£ swizzle, LDSM, MMA](https://zhuanlan.zhihu.com/p/934430036)
- [ä¸€æ–‡è¯»æ‡‚nsight systemä¸cuda kernelçš„æ—¶é—´çº¿åˆ†æä¸å¯è§†åŒ–](https://zhuanlan.zhihu.com/p/691307737)
- [TileLang: 80è¡ŒPython kernelä»£ç å®ç°FlashMLA 95%çš„æ€§èƒ½](https://zhuanlan.zhihu.com/p/27965825936)
- [ç®€å•CUDA Assemblyä»‹ç»](https://zhuanlan.zhihu.com/p/27455487044)
- [Deep Gemm ä»£ç æµ…æ](https://zhuanlan.zhihu.com/p/26916462532)
- [å¦‚ä½•çœ‹æ‡‚deepseek aiå¼€æºçš„FlashMLAä¸­çš„æ ¸å¿ƒcuä»£ç ï¼Ÿ](https://www.zhihu.com/question/13188512132/answer/113811134716)
- [æµ…æGEMMä¼˜åŒ–multistageæ•°æ€ä¹ˆç®—](https://zhuanlan.zhihu.com/p/714353243)
- [DeepSeek: FlashMLAä»£ç è§£æ](https://zhuanlan.zhihu.com/p/26269071923)
- [triton(openai)å¦‚ä½•å®ç°splitkå’Œstreamk?](https://www.zhihu.com/question/13143162788/answer/108685833211)
- [FlashMLAæ€§èƒ½ç®€æµ‹](https://zhuanlan.zhihu.com/p/26113545571)
- [DeepSeek-V3/R1 çš„ Hosting æˆæœ¬é¢„ä¼°](https://zhuanlan.zhihu.com/p/23282743306)
- [å®ç”¨ Swizzle æ•™ç¨‹ï¼ˆä¸€ï¼‰](https://zhuanlan.zhihu.com/p/20579515046)
- [å®ç”¨ Swizzle æ•™ç¨‹ï¼ˆäºŒï¼‰](https://zhuanlan.zhihu.com/p/21142007017)
- [CUDAç¼–ç¨‹å…¥é—¨ä¹‹Cooperative Groups(1)](https://zhuanlan.zhihu.com/p/572820342)

</details>

#### å¤§æ¨¡å‹Infraç›¸å…³åšå®¢ï¼ˆDeepSeekï¼ŒVERL, Megatron-LM, SGLangï¼ŒvLLMç­‰ï¼‰

<details>
<summary>ç‚¹å‡»å±•å¼€/æ”¶èµ· å¤§æ¨¡å‹Infraä¼˜è´¨åšå®¢åˆ—è¡¨</summary>

- [Megatron-LM åˆ†å¸ƒå¼æ‰§è¡Œè°ƒç ”](https://strint.notion.site/Megatron-LM-86381cfe51184b9c888be10ee82f3812)
- [BLOOM è®­ç»ƒèƒŒåçš„æŠ€æœ¯](https://www.cnblogs.com/Matrix_Yao/p/17238627.html)
- [èŠèŠ PyTorch2.0 ä¸­æ–°çš„Distributed API](https://mp.weixin.qq.com/s/hOOFE_eFD6a8GKTdnRcJXg)
- [èŠèŠ PyTorch ä¸­æ–°çš„Distributed API ï¼ˆäºŒï¼‰](https://mp.weixin.qq.com/s/zDSuToVMo4iK3sxF662kvg)
- [ã€LLMã€‘ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹](https://zhuanlan.zhihu.com/p/636270877)
- [åœ¨ä¸€å¼  24 GB çš„æ¶ˆè´¹çº§æ˜¾å¡ä¸Šç”¨ RLHF å¾®è°ƒ 20B LLMs](https://www.cnblogs.com/huggingface/p/17245966.html)
- [äººæ‰‹ä¸€ä¸ªChatGPTï¼å¾®è½¯DeepSpeed Chatéœ‡æ’¼å‘å¸ƒï¼Œä¸€é”®RLHFè®­ç»ƒåƒäº¿çº§å¤§æ¨¡å‹](https://zhuanlan.zhihu.com/p/621379646)
- [å¤§å‹è¯­è¨€æ¨¡å‹(LLM)è®­ç»ƒæŒ‡å—ğŸš€](https://zhuanlan.zhihu.com/p/611325149)
- [â€œStackLLaMAâ€: ç”¨ RLHF è®­ç»ƒ LLaMA çš„æ‰‹æŠŠæ‰‹æ•™ç¨‹](https://zhuanlan.zhihu.com/p/626896135)
- [å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰ï¼Œä»¥Gpipeä¸ºä¾‹](https://zhuanlan.zhihu.com/p/613196255)
- [å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæ•°æ®å¹¶è¡Œä¸Šç¯‡(DP, DDPä¸ZeRO)](https://zhuanlan.zhihu.com/p/617133971)
- [å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæ•°æ®å¹¶è¡Œä¸‹ç¯‡( DeepSpeed ZeROï¼Œé›¶å†—ä½™ä¼˜åŒ–)](https://zhuanlan.zhihu.com/p/618865052)
- [å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šå¼ é‡æ¨¡å‹å¹¶è¡Œ(TP)ï¼ŒMegatron-LM](https://zhuanlan.zhihu.com/p/622212228)
- [Megatron-LM ä¸­çš„ pipeline å¹¶è¡Œ](https://zhuanlan.zhihu.com/p/432969288)
- [å›¾è§£å¤§æ¨¡å‹ç³»åˆ—ä¹‹ï¼šMegatronæºç è§£è¯»1ï¼Œåˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–](https://zhuanlan.zhihu.com/p/629121480)
- [å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šMegatronæºç è§£è¯»2ï¼Œæ¨¡å‹å¹¶è¡Œ](https://zhuanlan.zhihu.com/p/634377071)
- [èŠèŠåºåˆ—å¹¶è¡ŒSequence parallelism](https://mp.weixin.qq.com/s/ylScQOpJ1-ufyPK7X6VUjw)
- [æ·±å…¥ç†è§£ Megatron-LMï¼ˆ1ï¼‰åŸºç¡€çŸ¥è¯†](https://zhuanlan.zhihu.com/p/650234985)
- [æ·±å…¥ç†è§£ Megatron-LMï¼ˆ2ï¼‰åŸç†ä»‹ç»](https://zhuanlan.zhihu.com/p/650383289)
- [æ·±å…¥ç†è§£ Megatron-LMï¼ˆ3ï¼‰ä»£ç ç»“æ„](https://zhuanlan.zhihu.com/p/650237820)
- [æ·±å…¥ç†è§£ Megatron-LMï¼ˆ4ï¼‰å¹¶è¡Œè®¾ç½®](https://zhuanlan.zhihu.com/p/650500590)
- [æ·±å…¥ç†è§£ Megatron-LMï¼ˆ5ï¼‰å¼ é‡å¹¶è¡Œ](https://zhuanlan.zhihu.com/p/650237833)
- [èŠèŠå­—èŠ‚ AML ä¸‡å¡å·¥ä½œ MegaScale: Scaling Large Language Model Training](https://mp.weixin.qq.com/s/aXsURbHZKzoBw-ChaBnjEQ)
- [æ·±åº¦å­¦ä¹ é‡Œï¼Œæ¨¡å‹å¹¶è¡Œä¸­æ€ä¹ˆå°†æ¨¡å‹æ‹†åˆ†ï¼Ÿ](https://www.zhihu.com/question/319355346/answer/2985459442)
- [Transformers DeepSpeedå®˜æ–¹æ–‡æ¡£](https://zhuanlan.zhihu.com/p/621572871)
- [DeepSeek-V3 MTP å·¥ç¨‹å®ç°æ€è€ƒ](https://zhuanlan.zhihu.com/p/29082207943)
- [DeepSeek V3/R1 æ¨ç†æ•ˆç‡åˆ†æï¼ˆ1ï¼‰ï¼šå…³äºDeepSeek V3/R1 Decodingååæé™çš„ä¸€äº›ä¸è´Ÿè´£ä»»ä¼°è®¡](https://zhuanlan.zhihu.com/p/27292649125)
- [DeepSeek V3/R1 æ¨ç†æ•ˆç‡åˆ†æï¼ˆ2ï¼‰: DeepSeek æ»¡è¡€ç‰ˆé€†å‘å·¥ç¨‹åˆ†æ](https://zhuanlan.zhihu.com/p/29841050824)
- [DeepSeek V3/R1 æ¨ç†æ•ˆç‡åˆ†æï¼ˆ3ï¼‰ï¼šDecode é…ç½®æ³›åŒ–è®¨è®º](https://zhuanlan.zhihu.com/p/29540042383)
- [å¦‚ä½•ä¼°ç®—ä¸åŒè§„æ ¼çš„èŠ¯ç‰‡ EP éƒ¨ç½² Deepseek çš„å•å¡åå V1.0](https://zhuanlan.zhihu.com/p/30471846931)
- [æ·±åº¦è§£æFlashMLA: ä¸€æ–‡è¯»æ‡‚å¤§æ¨¡å‹åŠ é€Ÿæ–°åˆ©å™¨](https://zhuanlan.zhihu.com/p/27976368445)
- [MoE Inference On AnyScale](https://zhuanlan.zhihu.com/p/28680264165)
- [[AI Infra] VeRL æ¡†æ¶å…¥é—¨&ä»£ç å¸¦è¯»](https://zhuanlan.zhihu.com/p/27676081245)
- [å¤§æ¨¡å‹åˆ†å¸ƒå¼é€šä¿¡æŠ€æœ¯åšå®¢æ±‡æ€»](https://zhuanlan.zhihu.com/p/30451575581)
- [sglang æºç å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰- Cacheã€Reqä¸Scheduler](https://zhuanlan.zhihu.com/p/17186885141)
- [DualPipe æ·±å…¥æµ…å‡ºï¼šæ²¡æœ‰åˆ†å¸ƒå¼è®­ç»ƒåŸºç¡€ä¹Ÿèƒ½çœ‹æ‡‚çš„ DualPipe å…¨æ–¹ä½è®²è§£](https://zhuanlan.zhihu.com/p/27045651854)
- [DeepSeek MLAå¼•å‘çš„ä¸€äº›è®°å¿†ç¢ç‰‡](https://zhuanlan.zhihu.com/p/25210365944)
- [DeepSeek MLAçš„åºåˆ—å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œ](https://zhuanlan.zhihu.com/p/25573883266)
- [SGLang: Tritonç®—å­extend_attention/Prefixä¼˜åŒ–](https://zhuanlan.zhihu.com/p/22996351654)
- [DeepSeek-V3 (671B) æ¨¡å‹å‚æ•°é‡åˆ†è§£è®¡ç®—](https://zhuanlan.zhihu.com/p/21455638257)
- [PP->VPP->ZeroBubblePP->deepseekv3 dualPipeï¼Œå¯¹PP bubbleçš„æè‡´å‹ç¼©](https://zhuanlan.zhihu.com/p/26559590326)
- [åŒæµå¹¶è¡Œ(DualPipe) æ²¡æœ‰åŒæµä¼šæ›´å¥½](https://zhuanlan.zhihu.com/p/26915547331)
- [deepseek è®­ç»ƒ profile data åŸºç¡€åˆ†æ](https://zhuanlan.zhihu.com/p/26717172494)
- [Deepseek FlashMLAè§£æ](https://zhuanlan.zhihu.com/p/26262350225)
- [ç»™ Megatron çš„é•¿æ–‡æœ¬è®­ç»ƒæŠ“äº†ä¸€ä¸ª Bug](https://zhuanlan.zhihu.com/p/26109356836)
- [å¯¹DualPipeçš„ä¸€äº›æƒ³æ³•](https://zhuanlan.zhihu.com/p/21525151726)
- [SGLang: Tritonç®—å­prefill_attention](https://zhuanlan.zhihu.com/p/19989050229)
- [[CUDAåŸºç¡€]ğŸ“šCUDA-Learn-Notes: v3.0 å¤§å‡çº§-é¢è¯•åˆ·é¢˜ä¸è¿·è·¯](https://zhuanlan.zhihu.com/p/19862356369)

</details>

## Star History


<a href="https://star-history.com/#BBuf/how-to-optim-algorithm-in-cuda&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=BBuf/how-to-optim-algorithm-in-cuda&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=BBuf/how-to-optim-algorithm-in-cuda&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=BBuf/how-to-optim-algorithm-in-cuda&type=Date" />
  </picture>
</a>